import cv2
import numpy as np
from pathlib import Path
import glob
import cv2
import os


# ---------- ä½ å·²æœ‰çš„å·¥å…·ï¼ˆç•¥æœ‰æ”¹åŠ¨/å¤ç”¨ï¼‰ ----------
def load_img(path):
    img = cv2.imread(str(path), cv2.IMREAD_COLOR)
    if img is None:
        raise FileNotFoundError(f"Cannot read image: {path}")
    return img

def sift_keypoints_and_descriptors(img_gray):
    sift = cv2.SIFT_create()
    kp, des = sift.detectAndCompute(img_gray, None)
    return kp, des

def match_descriptors(des1, des2, ratio=0.8):
    FLANN_INDEX_KDTREE = 1
    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
    search_params = dict(checks=100)
    flann = cv2.FlannBasedMatcher(index_params, search_params)
    knn = flann.knnMatch(des1, des2, k=2)
    good = []
    for m, n in knn:
        if m.distance < ratio * n.distance:
            good.append(m)
    return good

def estimate_homography(kp1, kp2, matches, ransac_thresh=4.0):
    if len(matches) < 4:
        return None, None, 0
    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches])
    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches])
    H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, ransac_thresh)
    inliers = int(mask.sum()) if (mask is not None) else 0
    return H, mask, inliers

# ---------- å…³é”®ï¼šæŠŠå¤šå¼ å›¾éƒ½é…å‡†åˆ° reference(-90deg) ----------
def register_to_reference(img, ref_img, kp_ref, des_ref, ratio=0.8, ransac_thresh=4.0):
    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    kp, des = sift_keypoints_and_descriptors(g)
    if des is None or len(kp) < 4:
        return None, [], 0
    matches = match_descriptors(des, des_ref, ratio=ratio)
    H, mask, inliers = estimate_homography(kp, kp_ref, matches, ransac_thresh=ransac_thresh)
    return H, matches, inliers

def compute_global_canvas(h_ref, w_ref, transforms):
    """
    transforms: [(img, H_ref_from_img), ...]ï¼Œæ³¨æ„åŒ…å« (ref_img, I)
    è®¡ç®—æ‰€æœ‰å›¾çš„å››è§’ç»å˜æ¢åçš„èŒƒå›´ï¼Œå¾—åˆ°å…¨æ™¯ç”»å¸ƒå’Œç”¨äºæ­£åæ ‡çš„å¹³ç§» Tã€‚
    """
    corners_all = []
    for img, H in transforms:
        h, w = img.shape[:2]
        corners = np.float32([[0,0],[w,0],[w,h],[0,h]]).reshape(-1,1,2)
        warp = cv2.perspectiveTransform(corners, H)
        corners_all.append(warp)

    all_corners = np.vstack(corners_all)
    xmin, ymin = np.floor(all_corners.min(axis=0).ravel()).astype(int)
    xmax, ymax = np.ceil(all_corners.max(axis=0).ravel()).astype(int)

    tx, ty = -xmin, -ymin
    T = np.array([[1,0,tx],[0,1,ty],[0,0,1]], dtype=np.float64)
    width, height = (xmax - xmin), (ymax - ymin)
    return T, width, height

def feather_blend(dst, src, mask):
    """
    ç®€å•ç¾½åŒ–èåˆï¼šæŒ‰è·ç¦»è¾¹ç•Œçš„æƒé‡çº¿æ€§èåˆã€‚
    dst: ç›®æ ‡å…¨æ™¯ç”»å¸ƒ (H,W,3)
    src: åŒå°ºå¯¸çš„å¾…èåˆå›¾ (H,W,3)
    mask: åŒå°ºå¯¸å•é€šé“(0/1)ï¼Œsrcæœ‰æ•ˆåŒºåŸŸ
    """
    if mask.max() == 0:
        return dst
    # è·ç¦»å˜æ¢ä½œä¸ºæƒé‡
    inv_mask = (1 - mask).astype(np.uint8)
    dist_dst = cv2.distanceTransform(inv_mask, cv2.DIST_L2, 3)
    dist_src = cv2.distanceTransform((1 - inv_mask), cv2.DIST_L2, 3)  # == mask
    weight_src = dist_src / (dist_src + dist_dst + 1e-6)
    weight_src = weight_src[..., None]  # (H,W,1)

    dst_f = dst.astype(np.float32)
    src_f = src.astype(np.float32)
    out = (dst_f * (1 - weight_src) + src_f * weight_src)
    return out.astype(np.uint8)

def warp_into_canvas(img, H, T, size):
    """
    æŠŠ img ç» T@H å˜æ¢åˆ°ç”»å¸ƒ size=(W,H)ï¼Œè¿”å›å˜æ¢å›¾å’Œæœ‰æ•ˆåŒºåŸŸmask
    """
    W, Hh = size
    M = T @ H
    warped = cv2.warpPerspective(img, M, (W, Hh))
    mask = cv2.warpPerspective(np.ones(img.shape[:2], dtype=np.uint8), M, (W, Hh))
    mask = (mask > 0).astype(np.uint8)
    return warped, mask

def stitch_all_to_minus90(image_paths, ref_path):
    # è¯»å– reference
    ref_img = load_img(ref_path)
    g_ref = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)
    kp_ref, des_ref = sift_keypoints_and_descriptors(g_ref)

    transforms = [(ref_img, np.eye(3, dtype=np.float64))]
    H_map = {str(ref_path): np.eye(3, dtype=np.float64)}  # è®°å½•å‚è€ƒå›¾è‡ªèº«ä¸º I

    failed = []
    for p in image_paths:
        if str(p) == str(ref_path):
            continue
        img = load_img(p)
        H, matches, inliers = register_to_reference(
            img, ref_img, kp_ref, des_ref, ratio=0.8, ransac_thresh=4.0
        )
        if H is None:
            failed.append((str(p), "H=None / insufficient matches"))
            continue
        transforms.append((img, H))
        H_map[str(p)] = H  # ğŸ‘ˆ ä¿å­˜ï¼šè¯¥å›¾ -> å‚è€ƒå›¾ çš„å•åº”çŸ©é˜µ

    # è®¡ç®—ç»Ÿä¸€ç”»å¸ƒ
    T, W, Hh = compute_global_canvas(ref_img.shape[0], ref_img.shape[1], transforms)

    panorama = np.zeros((Hh, W, 3), dtype=np.uint8)
    for img, H in transforms:
        warped, mask = warp_into_canvas(img, H, T, (W, Hh))
        if panorama.sum() == 0:
            panorama = warped
        else:
            warped_bg = warped.copy()
            warped_bg[mask == 0] = 0
            panorama = feather_blend(panorama, warped_bg, mask)

    return panorama, transforms, failed, T, H_map

import re
from collections import defaultdict

def parse_angle_from_path(p):
    """
    ä»æ–‡ä»¶åä¸­è§£æè§’åº¦ï¼Œå½¢å¦‚ scene_-90deg.jpg -> -90
    """
    m = re.search(r'_(\-?\d+)deg\.jpg$', os.path.basename(str(p)))
    return int(m.group(1)) if m else None

def register_pairwise(img_src, img_tgt, kp_tgt, des_tgt, ratio=0.8, ransac_thresh=4.0):
    """
    æŠŠ img_src é…å‡†åˆ°ç›®æ ‡ img_tgtï¼Œè¿”å› H_tgt_from_srcï¼ˆä» src åˆ° tgt çš„å•åº”ï¼‰
    """
    g = cv2.cvtColor(img_src, cv2.COLOR_BGR2GRAY)
    kp_src, des_src = sift_keypoints_and_descriptors(g)
    if des_src is None or len(kp_src) < 4:
        return None, 0
    matches = match_descriptors(des_src, des_tgt, ratio=ratio)
    H, mask, inliers = estimate_homography(kp_src, kp_tgt, matches, ransac_thresh=ransac_thresh)
    return H, inliers

def pano_stitch_subset_and_map_all(
    image_paths, 
    ref_path, 
    anchor_range=(-110, -70),  # åªç”¨è¿™ä¸ªè§’åº¦åŒºé—´çš„è§†è§’å‚ä¸æ‹¼æ¥
    ratio=0.8, 
    ransac_thresh=4.0
):
    # 1) è¯»å–å‚è€ƒå›¾ï¼ˆ-90ï¼‰
    ref_img = load_img(ref_path)
    g_ref = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)
    kp_ref, des_ref = sift_keypoints_and_descriptors(g_ref)

    # 2) æŒ‰è§’åº¦åˆ’åˆ† â€œé”šå®šè§†è§’â€ ä¸ â€œä»…æ˜ å°„è§†è§’â€
    anchors, map_only = [], []
    ref_angle = parse_angle_from_path(ref_path)
    for p in image_paths:
        if str(p) == str(ref_path):
            anchors.append(p)  # å‚è€ƒä¸€å®šåœ¨é”šå®šé›†
            continue
        a = parse_angle_from_path(p)
        if a is not None and (anchor_range[0] <= a <= anchor_range[1]):
            anchors.append(p)
        else:
            map_only.append(p)

    # 3) å…ˆæŠŠé”šå®šè§†è§’éƒ½é…å‡†åˆ°å‚è€ƒï¼ˆç”¨äºç”»å¸ƒä¸èåˆï¼‰
    transforms = [(ref_img, np.eye(3, dtype=np.float64))]
    H_map = {str(ref_path): np.eye(3, dtype=np.float64)}
    failed_anchor = []

    # ä¹Ÿç¼“å­˜é”šå®šè§†è§’çš„ SIFTï¼Œä»¥ä¾¿éé”šå®šè§†è§’èµ°â€œå…ˆåˆ°é”šå®šâ€çš„åå¤‡è·¯çº¿
    anchor_cache = {}  # path -> dict(img, kp, des, H_ref_from_anchor)
    anchor_cache[str(ref_path)] = {
        "img": ref_img, "kp": kp_ref, "des": des_ref, "H_ref": np.eye(3, dtype=np.float64),
        "angle": ref_angle
    }

    for p in anchors:
        if str(p) == str(ref_path):
            continue
        img = load_img(p)
        H, matches, inliers = register_to_reference(
            img, ref_img, kp_ref, des_ref, ratio=ratio, ransac_thresh=ransac_thresh
        )
        if H is None:
            failed_anchor.append((str(p), "anchor->ref failed"))
            continue
        transforms.append((img, H))
        H_map[str(p)] = H

        # ç¼“å­˜é”šå®šè§†è§’çš„ç‰¹å¾
        g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        kp, des = sift_keypoints_and_descriptors(g)
        anchor_cache[str(p)] = {
            "img": img, "kp": kp, "des": des, "H_ref": H,
            "angle": parse_angle_from_path(p)
        }

    # 4) è®¡ç®—ç”»å¸ƒï¼ˆåªç”¨é”šå®šè§†è§’ï¼‰
    T, W, Hh = compute_global_canvas(ref_img.shape[0], ref_img.shape[1], transforms)

    # 5) åªèåˆé”šå®šè§†è§’
    panorama = np.zeros((Hh, W, 3), dtype=np.uint8)
    first = True
    for img, H in transforms:
        warped, mask = warp_into_canvas(img, H, T, (W, Hh))
        if first:
            panorama = warped
            first = False
        else:
            warped_bg = warped.copy()
            warped_bg[mask == 0] = 0
            panorama = feather_blend(panorama, warped_bg, mask)

    # 6) ä¸º map-only è§†è§’æ±‚ H_ref_from_imgï¼ˆä¸å‚ä¸èåˆï¼‰
    failed_maponly = []
    # å…ˆå‡†å¤‡ä¸€ä¸ªæŒ‰è§’åº¦çš„é”šå®šåˆ—è¡¨ï¼Œä¾¿äºæ‰¾â€œæœ€è¿‘é”šå®šâ€
    anchor_list = [
        (info["angle"], path, info) for path, info in anchor_cache.items() if info["angle"] is not None
    ]
    for p in map_only:
        img = load_img(p)

        # 6.1 ç›´è¿åˆ°å‚è€ƒ
        H_direct, matches, inliers = register_to_reference(
            img, ref_img, kp_ref, des_ref, ratio=ratio, ransac_thresh=ransac_thresh
        )
        if H_direct is not None:
            H_map[str(p)] = H_direct
            continue

        # 6.2 å¤±è´¥åˆ™æ‰¾æœ€è¿‘è§’åº¦çš„é”šå®šè§†è§’ï¼Œå…ˆé…å‡†åˆ°é”šå®šï¼Œå†é“¾å¼åˆ°å‚è€ƒ
        a = parse_angle_from_path(p)
        best = None
        if a is not None and len(anchor_list) > 0:
            best = min(anchor_list, key=lambda x: abs(a - x[0]))  # (angle, path, info)

        if best is not None:
            _, anchor_path, info = best
            H_anchor, inliers2 = register_pairwise(img, info["img"], info["kp"], info["des"],
                                                  ratio=ratio, ransac_thresh=ransac_thresh)
            if H_anchor is not None:
                # é“¾å¼ï¼šimg -> anchor -> ref
                H_ref = info["H_ref"] @ H_anchor
                H_map[str(p)] = H_ref
                continue

        # 6.3 ä»å¤±è´¥åˆ™è®°å½•
        failed_maponly.append((str(p), "map-only failed to register (direct & via anchor)"))

    # ä¿å­˜ç”»å¸ƒå¹³ç§»
    H_map['T'] = T
    H_map['canvas_size'] = np.array([W, Hh], dtype=np.int32)

    return panorama, transforms, failed_anchor, failed_maponly, T, H_map

def project_points_to_pano(points_xy, H_ref_from_img, T):
    """
    æŠŠæŸè§†è§’ä¸Šçš„ç‚¹æŠ•åˆ° pano ç”»å¸ƒåæ ‡ç³»
    """
    pts = np.asarray(points_xy, dtype=np.float32).reshape(-1,1,2)
    M = T @ H_ref_from_img
    proj = cv2.perspectiveTransform(pts, M).reshape(-1,2)
    return proj

# ----------------- ä½¿ç”¨ç¤ºä¾‹ -----------------
# ä»¥ -90deg ä¸ºå‚è€ƒï¼ŒæŠŠåŒåœºæ™¯ä¸åŒè§’åº¦éƒ½æ‹¼è¿›å»
# H_maps = {}  # ä¿å­˜æ¯ä¸ªå›¾åˆ° -90 çš„å•åº”çŸ©é˜µ
# for scene in ["livingroom", "kidroom", "workshop", "studyroom"]:
#     ref_path = Path(f"scenes/{scene}/norm/{scene}_-90deg.jpg")
#     image_paths = [Path(i) for i in glob.glob(f"scenes/{scene}/norm/*.jpg") if os.path.exists(f"annotations/{os.path.basename(i).replace('.jpg', '.json')}")]

#     panorama, transforms, failed, T, H_map = stitch_all_to_minus90(image_paths, ref_path)
#     # H_maps[scene] = H_map  # ä¿å­˜æ¯ä¸ªåœºæ™¯çš„ H_map
#     H_map['T'] = T
#     np.savez(f"metadata/{scene}_H.npz", **{k: H_map[k] for k in H_map})
#     cv2.imwrite(f"metadata/{scene}_panorama.jpg", panorama)
#     print("Failed:", failed)

# # å¦‚æœä½ æœ‰ä¸€æ¡åœ¨ angleX ä¸Šçš„è½¨è¿¹ points_X (N,2)ï¼Œæƒ³æŠ•åˆ° -90ï¼š
# def project_traj_to_ref(points_xy, H_ref_from_img):
#     pts = np.asarray(points_xy, dtype=np.float32).reshape(-1,1,2)
#     proj = cv2.perspectiveTransform(pts, H_ref_from_img).reshape(-1,2)
#     return proj

if __name__ == "__main__":
    for scene in ["livingroom", "kidroom", "workshop", "studyroom"]:
        ref_path = Path(f"scenes/{scene}/norm/{scene}_-90deg.jpg")
        # è¿™é‡Œ image_paths å¯ä»¥ç»™â€œå…¨éƒ¨è§†è§’â€ï¼ˆå« -120ã€-130 ç­‰ï¼‰
        image_paths = [Path(i) for i in glob.glob(f"scenes/{scene}/norm/*.jpg") 
                    if os.path.exists(f"annotations/{os.path.basename(i).replace('.jpg', '.json')}")]

        pano, transforms, fail_anchor, fail_maponly, T, H_map = pano_stitch_subset_and_map_all(
            image_paths, ref_path, anchor_range=(-110, -70)
        )

        # å­˜å‚¨
        H_map_npz = {k: H_map[k] for k in H_map}
        np.savez(f"metadata/{scene}_H.npz", **H_map_npz)
        cv2.imwrite(f"metadata/{scene}_panorama.jpg", pano)
        print("Failed anchors:", fail_anchor)
        print("Failed map-only:", fail_maponly)